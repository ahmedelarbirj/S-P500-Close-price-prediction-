# -*- coding: utf-8 -*-
"""Copy of lstm multivariate S&P500.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18XesDyU1YEhTN0fXQwrxdVE-i3b_HNVt
"""

import math # Mathematical functions 
import numpy as np # Fundamental package for scientific computing with Python
import pandas as pd # Additional functions for analysing and manipulating data
from datetime import date, timedelta, datetime # Date Functions
from pandas.plotting import register_matplotlib_converters # This function adds plotting functions for calender dates
import matplotlib.pyplot as plt # Important package for visualization - we use this to plot the market data
import matplotlib.dates as mdates # Formatting dates
import tensorflow as tf
from sklearn.metrics import mean_absolute_error, mean_squared_error # Packages for measuring model performance / errors
from tensorflow.keras import Sequential # Deep learning library, used for neural networks
from tensorflow.keras.layers import LSTM, Dense, Dropout # Deep learning classes for recurrent and regular densely-connected layers
from tensorflow.keras.callbacks import EarlyStopping # EarlyStopping during model training
from sklearn.preprocessing import RobustScaler, MinMaxScaler # This Scaler removes the median and scales the data according to the quantile range to normalize the price data 
import seaborn as sns # Visualization
sns.set_style('white', { 'axes.spines.right': False, 'axes.spines.top': False})


# check the tensorflow version and the number of available GPUs
print('Tensorflow Version: ' + tf.__version__)
physical_devices = tf.config.list_physical_devices('GPU')
print("Num GPUs:", len(physical_devices))

# Setting the timeframe for the data extraction
end_date =  '2022-08-21'
start_date = '2007-01-01'

# Getting S&P500 quotes
stockname = 'S&P500'
symbol = '^GSPC'

# You can either use webreader or yfinance to load the data from yahoo finance
# import pandas_datareader as webreader
# df = webreader.DataReader(symbol, start=start_date, end=end_date, data_source="yahoo")
!pip install yfinance
import yfinance as yf #Alternative package if webreader does not work: pip install yfinance
dataset = yf.download(symbol, start=start_date, end=end_date)

# Quick overview of dataset
dataset.head()

import numpy as np
import pandas as pd
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM
from keras.models import Sequential
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt

!pip install talib-binary

import talib
from talib import (WILLR,ROC,CCI)

def get_technical_indicators(dataset): #function to generate feature technical indicators
    # Create 7 and 21 days Moving Average
    dataset['sma26'] = dataset['Close'].rolling(window = 26).mean()
    dataset['sma12'] = dataset['Close'].rolling(window = 12).mean()
    
    #Create MACD
    dataset['26ema'] = dataset['Close'].ewm(span=26).mean()
    dataset['12ema'] = dataset['Close'].ewm(span=12).mean()
    dataset['MACD'] = (dataset['12ema']-dataset['26ema'])
    
    #Create Bollinger Bands
    dataset['20sd'] = dataset['Close'].rolling(window = 20).std()
    dataset['upper_band'] = (dataset['Close'].rolling(window = 20).mean()) + (dataset['20sd']*2)
    dataset['lower_band'] = (dataset['Close'].rolling(window = 20).mean()) - (dataset['20sd']*2)
    
    #Create Exponential moving average
    dataset['ema'] = dataset['Close'].ewm(com=0.5).mean()
    
    # Moving Averages on high, lows, and std - different periods
    dataset['14-high'] = dataset['High'].rolling(14).max()
    dataset['14-low'] = dataset['Low'].rolling(14).min()
    dataset['%K'] = (dataset['Close'] - dataset['14-low'])*100/(dataset['14-high'] - dataset['14-low'])
    dataset['%D'] = dataset['%K'].rolling(3).mean() 
    
    # Relative Strength Index (RSI)
    dataset['K-ratio'] = 100*((dataset['Close'] - dataset['14-low']) / (dataset['14-high'] - dataset['14-low']) )
    dataset['RSI'] = dataset['K-ratio'].rolling(window=3).mean() 
    
    #william %R
    dataset['%R'] = WILLR(dataset['High'], dataset['Low'], dataset['Close'], timeperiod=14).round(3)
   
    #the rate of change ROC 
    dataset['ROC'] = ROC(dataset['Close'], 12)
    
    #CCI
    dataset['CCI'] =  CCI(dataset['High'], dataset['Low'], dataset['Close'], timeperiod=14)
    
    #Stoch RSI
    
    return dataset

dataset_TI = get_technical_indicators(dataset)
dataset_TI

import seaborn as sns
corr_df = dataset_TI.corr(method='pearson')
plt.figure(figsize=(16,14))
sns.heatmap(corr_df, annot=True)
plt.show()

#data = dataset_TI.loc[:,['Open', 'Close', 'RSI', 'upper_band', '%R', 'ROC', '26ema', 'CCI', 'MACD', '%K']]
#data = dataset_TI.loc[:,[  'RSI','Close', 'upper_band', 'lower_band', '%R', 'ROC', '12ema', '26ema', 'CCI', 'MACD', '%K']] #'Open', 'High', 'Low',
#data
data = dataset_TI.loc[:,[  'RSI', 'Close', 'upper_band', 'lower_band', '%R', 'ROC', "sma26", "sma12",'12ema', '26ema', 'CCI', 'MACD', '%K']] #'Open', 'High', 'Low',
data

def plot_technical_indicators(dataset):
    plt.figure(figsize=(24, 16), dpi=100)
    shape_0 = dataset.shape[0]
    xmacd_ = shape_0
    
    dataset = dataset.iloc[:, :]
    x_ = range(3, dataset.shape[0])
    x_ =list(dataset.index)
    
    # subplot
    plt.subplot(2, 1, 1)
    
    plt.plot(dataset['Close'],label='S&P500 Closing Price', color='k')
    #plt.plot(dataset['Open'],label='Open', color='#FFB90F',linestyle='--')
    #plt.plot(dataset['High'],label='High', color='r',linestyle='--')
    #plt.plot(dataset['Low'],label='Low', color='g',linestyle='--')
    plt.plot(dataset['upper_band'],label='upper_band', color='c')
    #plt.plot(dataset['lower_band'],label='lower_band', color='c')   
    plt.plot(dataset['26ema'],label='26ema', color='#CDB79E')
    plt.fill_between(x_, dataset['lower_band'], dataset['upper_band'], alpha=0.35)
    plt.title('Technical indicators for S&P500.')
    plt.ylabel('USD')
    plt.legend()

    plt.subplot(2, 1, 2)
    plt.title('')
    plt.plot(dataset['MACD'],label='MACD', linestyle='-.')
    plt.plot(dataset['RSI'],label='RSI', color='#FFB90F')
    plt.plot(dataset['ROC'],label='ROC', color='r')
    plt.plot(dataset['CCI'],label='CCI', color='#0000FF')
    plt.plot(dataset['%K'],label='%K', color='#7FFF00')
    #plt.hlines(1000, xmacd_, shape_0, colors='g', linestyles='--')
    #plt.hlines(-1000, xmacd_, shape_0, colors='g', linestyles='--')
   
    plt.legend()
    plt.show()

plot_technical_indicators(dataset_TI)

# delete a range of rows that contain at least 1 NaN
data = data.dropna()
data

import seaborn as sns
corr_df = data.corr(method='pearson')
plt.figure(figsize=(16,14))
sns.heatmap(corr_df, annot=True)
plt.show()

data.shape

features = data[[ 'RSI', 'Close', 'upper_band', '%R', 'ROC', 'sma26', '26ema', 'CCI', 'MACD', '%K']].values
features.shape

def create_datasets(dataset, sequence_length):
  sequence_length +=1
  seq_dataset = []
  for i in range(len(dataset)-sequence_length):
    seq_dataset.append(dataset[i: i+ sequence_length])

  seq_dataset = np.array(seq_dataset)
  #print("seq_dataset",seq_dataset.shape)
  data_x = seq_dataset[:, :-1]
  data_y = seq_dataset[:, -1,1:2] # 1:2 -> 'close' #2nd -> between 1 (2nd) and 2 (3rd) and we know [a,b[
  return data_x, data_y
scaler= MinMaxScaler(feature_range=(0, 1))
features_scaled = scaler.fit_transform(features)
train_size = int(len(features_scaled) *0.8)
#train_data_len = math.ceil(scaled_data.shape[0] * 0.8)
test_size = len(features_scaled)-train_size
train, test = features_scaled[0:train_size,:], features_scaled[train_size:len(features_scaled)]

look_back = 30 # sequence length

x_train, y_train = create_datasets(train,look_back)
x_test, y_test = create_datasets(test,look_back)

x_train.shape

y_train.shape

model = Sequential()

#model.add(LSTM(128,return_sequences=True))
model.add(LSTM(50, input_shape=(x_train.shape[1],x_train.shape[2]), return_sequences=False))
model.add(Dropout(0.35))
model.add(Dense(1))
model.add(Activation('linear'))

model.compile(loss='mse', optimizer = 'adam')

model.summary()

history= model.fit(x_train,y_train, batch_size=64, epochs=100, verbose=2, validation_split=0.2)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

train_predict = model.predict(x_train)
test_predict = model.predict(x_test)


scaler_label= MinMaxScaler(feature_range=(0, 1))
label_scaler= scaler_label.fit_transform(features[:,1:2])

train_predict_unnorm = scaler_label.inverse_transform(train_predict)
test_predict_unnorm = scaler_label.inverse_transform(test_predict)

print(train_predict_unnorm.mean())
print(train_predict.mean())
#creating similar dataset to plot training predictions
close_price = features[:,1:2]
trainpredictPlot= np.empty_like(close_price)

print(trainpredictPlot.shape)
trainpredictPlot[look_back:len(train_predict_unnorm)+look_back, :] = train_predict_unnorm
#creating similar dataset to plot test prediction
testpredictPlot = np.empty_like(close_price)
testpredictPlot[:, :] = np.nan 
#testpredictPlot[len(train_predict_unnorm)+(look_back*2)+30:len(close_price)-10, :] = test_predict_unnorm #30=1, 10=1
testpredictPlot[len(train_predict_unnorm)+(look_back*2)+1:len(close_price)-1, :] = test_predict_unnorm #30=1, 10=1

plt.figure(figsize=(19,10))
plt.plot(close_price, 'g', label= 'original dataset')
plt.plot(trainpredictPlot, 'r', label= 'training dataset')
plt.plot(testpredictPlot, 'b', label= 'predicted and test')
plt.legend(loc= 'upper left')
plt.xlabel('Time in days')
plt.ylabel('price')
plt.title('S&P500')
plt.show()

from sklearn.metrics import mean_absolute_percentage_error,mean_squared_error,max_error,r2_score
# Mean Absolute Percentage Error (MAPE)
e1 = mean_absolute_percentage_error(y_test, test_predict)
e2 = mean_squared_error(y_test, test_predict)
e3 = r2_score(y_test, test_predict)
print("MAPE=",e1)
print("MSE=",e2)
print("r2_score=",e3)